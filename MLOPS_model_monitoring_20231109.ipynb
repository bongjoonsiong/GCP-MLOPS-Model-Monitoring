{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9vS6X5KIxGUr89BYCzfgI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bongjoonsiong/GCP-MLOPS-Model-Monitoring/blob/main/MLOPS_model_monitoring_20231109.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Monitoring Vertex AI Model"
      ],
      "metadata": {
        "id": "IGVusdnPjf2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is Model Monitoring?\n",
        "\n",
        "Modern applications rely on a well established set of capabilities to monitor the health of their services. Examples include:\n",
        "\n",
        "* software versioning\n",
        "* rigorous deployment processes\n",
        "* event logging\n",
        "* alerting/notification of situations requiring intervention\n",
        "* on-demand and automated diagnostic tracing\n",
        "* automated performance and functional testing\n",
        "\n",
        "You should be able to manage your ML services with the same degree of power and flexibility with which you can manage your applications. That's what MLOps is all about - managing ML services with the best practices Google and the broader computing industry have learned from generations of experience deploying well engineered, reliable, and scalable services.\n",
        "\n",
        "Model monitoring is only one piece of the ML Ops puzzle - it helps answer the following questions:\n",
        "\n",
        "* How well do recent service requests match the training data used to build your model? This is called **training-serving skew**.\n",
        "* How significantly are service requests evolving over time? This is called **drift detection**.\n",
        "\n",
        "If production traffic differs from  training data, or varies substantially over time, that's likely to impact the quality of the answers your model produces. When that happens, you'd like to be alerted automatically and responsively, so that **you can anticipate problems before they affect your customer experiences or your revenue streams**."
      ],
      "metadata": {
        "id": "3UuMmwKEjlZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning Objectives\n",
        "Deploy a pre-trained model.\n",
        "Configure model monitoring.\n",
        "Generate some artificial traffic.\n",
        "Interpret the data reported by the model monitoring feature."
      ],
      "metadata": {
        "id": "Bo5GUKSZjsXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduction\n",
        "In this notebook, you will deploy a pre-trained model to an endpoint and generate some prediction requests on the model. You will also create a monitoring job to keep an eye on the model quality and generate test data to trigger alerting."
      ],
      "metadata": {
        "id": "O9tj8P1FjyeH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The example model\n",
        "The model you'll use in this notebook is based on this blog post. The idea behind this model is that your company has extensive log data describing how your game users have interacted with the site. The raw data contains the following categories of information:\n",
        "\n",
        "identity - unique player identitity numbers\n",
        "demographic features - information about the player, such as the geographic region in which a player is located\n",
        "behavioral features - counts of the number of times a player has triggered certain game events, such as reaching a new level\n",
        "churn propensity - this is the label or target feature, it provides an estimated probability that this player will churn, i.e. stop being an active player.\n",
        "The blog article referenced above explains how to use BigQuery to store the raw data, pre-process it for use in machine learning, and train a model. Because this notebook focuses on model monitoring, rather than training models, you're going to reuse a pre-trained version of this model, which has been exported to Google Cloud Storage. In the next section, you will setup your environment and import this model into your own project.\n",
        "\n",
        "Each learning objective will correspond to a #TODO in this student lab notebook -- try to complete this notebook first and then review the Solution Notebook for reference."
      ],
      "metadata": {
        "id": "wmaIBJy7jzwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Before you begin"
      ],
      "metadata": {
        "id": "334RALyXj23B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup your dependencies"
      ],
      "metadata": {
        "id": "5WqWtpF9j521"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# The Google Cloud Notebook product has specific requirements\n",
        "IS_GOOGLE_CLOUD_NOTEBOOK = os.path.exists(\"/opt/deeplearning/metadata/env_version\")\n",
        "\n",
        "# Google Cloud Notebook requires dependencies to be installed with '--user'\n",
        "USER_FLAG = \"\"\n",
        "if IS_GOOGLE_CLOUD_NOTEBOOK:\n",
        "    USER_FLAG = \"--user\""
      ],
      "metadata": {
        "id": "6cbhDVkujZ45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import IPython\n",
        "\n",
        "assert sys.version_info.major == 3, \"This notebook requires Python 3.\"\n",
        "\n",
        "# Install Python package dependencies.\n",
        "# Upgrade the specified packages to the available versions\n",
        "print(\"Installing TensorFlow Data Validation (TFDV)\")\n",
        "! pip3 install {USER_FLAG} --quiet --upgrade tensorflow_data_validation[visualization]\n",
        "! pip3 install {USER_FLAG} --quiet --upgrade google-api-python-client google-auth-oauthlib google-auth-httplib2 oauth2client requests\n",
        "! pip3 install {USER_FLAG} --quiet --upgrade google-cloud-aiplatform\n",
        "! pip3 install {USER_FLAG} --quiet --upgrade google-cloud-storage\n",
        "\n",
        "# Automatically restart kernel after installing new packages.\n",
        "if not os.getenv(\"IS_TESTING\"):\n",
        "    print(\"Restarting kernel...\")\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)\n",
        "    print(\"Done.\")"
      ],
      "metadata": {
        "id": "zP85jpdpkBy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import sys\n",
        "import time\n",
        "\n",
        "# Import required packages.\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_HAZQDOokFpu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}